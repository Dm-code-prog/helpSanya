{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           звучать базар блатной мотив проясняться небо\n",
       "1      преградить путь закричать кинуться грудь приве...\n",
       "2                                       муза бестолковый\n",
       "3                                          убить молодой\n",
       "4      улица вечный печаль дом родимый сливаться зака...\n",
       "                             ...                        \n",
       "139    право являться б шорох отечество б подобный по...\n",
       "140    выпь пять минута прилечь проснуться ан жизнь п...\n",
       "141                                       прощать любовь\n",
       "142      исчезнуть фартучек манжета они весь ажурный мир\n",
       "143    домофон загудеть телефон зазвонить суетанадо д...\n",
       "Name: stolbec, Length: 144, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "stopwords = stopwords.words('russian')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in (stopwords)])\n",
    "    morph = pm.MorphAnalyzer()\n",
    "    text = ' '.join([morph.parse(word)[0].normal_form for word in text.split()])\n",
    "    return text\n",
    "# apply remove_punctuation to df['stolbec'] \n",
    "df['stolbec'] = df['stolbec'].apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6206896551724138"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['stolbec'], df['answer'], test_size=0.2, random_state=42) \n",
    "CV = CountVectorizer()\n",
    "X_train_counts = CV.fit_transform(X_train)\n",
    "X_test_counts = CV.transform(X_test)\n",
    "clf = LogisticRegression(max_iter=10000, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "clf.fit(X_train_counts, y_train)\n",
    "clf.score(X_test_counts, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts=X_train_counts.toarray()\n",
    "X_test_counts=X_test_counts.toarray()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 - 1s - loss: 0.6838 - accuracy: 0.5304 - 1s/epoch - 259ms/step\n",
      "Epoch 2/30\n",
      "4/4 - 0s - loss: 0.6362 - accuracy: 0.6000 - 61ms/epoch - 15ms/step\n",
      "Epoch 3/30\n",
      "4/4 - 0s - loss: 0.5383 - accuracy: 0.8087 - 60ms/epoch - 15ms/step\n",
      "Epoch 4/30\n",
      "4/4 - 0s - loss: 0.4693 - accuracy: 0.9217 - 78ms/epoch - 19ms/step\n",
      "Epoch 5/30\n",
      "4/4 - 0s - loss: 0.3470 - accuracy: 0.9217 - 81ms/epoch - 20ms/step\n",
      "Epoch 6/30\n",
      "4/4 - 0s - loss: 0.2541 - accuracy: 1.0000 - 64ms/epoch - 16ms/step\n",
      "Epoch 7/30\n",
      "4/4 - 0s - loss: 0.1826 - accuracy: 0.9826 - 66ms/epoch - 17ms/step\n",
      "Epoch 8/30\n",
      "4/4 - 0s - loss: 0.1311 - accuracy: 1.0000 - 59ms/epoch - 15ms/step\n",
      "Epoch 9/30\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 1.0000 - 73ms/epoch - 18ms/step\n",
      "Epoch 10/30\n",
      "4/4 - 0s - loss: 0.0616 - accuracy: 1.0000 - 74ms/epoch - 19ms/step\n",
      "Epoch 11/30\n",
      "4/4 - 0s - loss: 0.0429 - accuracy: 1.0000 - 65ms/epoch - 16ms/step\n",
      "Epoch 12/30\n",
      "4/4 - 0s - loss: 0.0293 - accuracy: 1.0000 - 78ms/epoch - 19ms/step\n",
      "Epoch 13/30\n",
      "4/4 - 0s - loss: 0.0226 - accuracy: 1.0000 - 66ms/epoch - 16ms/step\n",
      "Epoch 14/30\n",
      "4/4 - 0s - loss: 0.0162 - accuracy: 1.0000 - 68ms/epoch - 17ms/step\n",
      "Epoch 15/30\n",
      "4/4 - 0s - loss: 0.0125 - accuracy: 1.0000 - 62ms/epoch - 15ms/step\n",
      "Epoch 16/30\n",
      "4/4 - 0s - loss: 0.0077 - accuracy: 1.0000 - 72ms/epoch - 18ms/step\n",
      "Epoch 17/30\n",
      "4/4 - 0s - loss: 0.0054 - accuracy: 1.0000 - 70ms/epoch - 17ms/step\n",
      "Epoch 18/30\n",
      "4/4 - 0s - loss: 0.0044 - accuracy: 1.0000 - 70ms/epoch - 17ms/step\n",
      "Epoch 19/30\n",
      "4/4 - 0s - loss: 0.0028 - accuracy: 1.0000 - 83ms/epoch - 21ms/step\n",
      "Epoch 20/30\n",
      "4/4 - 0s - loss: 0.0028 - accuracy: 1.0000 - 68ms/epoch - 17ms/step\n",
      "Epoch 21/30\n",
      "4/4 - 0s - loss: 0.0024 - accuracy: 1.0000 - 65ms/epoch - 16ms/step\n",
      "Epoch 22/30\n",
      "4/4 - 0s - loss: 0.0020 - accuracy: 1.0000 - 67ms/epoch - 17ms/step\n",
      "Epoch 23/30\n",
      "4/4 - 0s - loss: 0.0013 - accuracy: 1.0000 - 69ms/epoch - 17ms/step\n",
      "Epoch 24/30\n",
      "4/4 - 0s - loss: 9.1422e-04 - accuracy: 1.0000 - 63ms/epoch - 16ms/step\n",
      "Epoch 25/30\n",
      "4/4 - 0s - loss: 4.1892e-04 - accuracy: 1.0000 - 59ms/epoch - 15ms/step\n",
      "Epoch 26/30\n",
      "4/4 - 0s - loss: 6.5456e-04 - accuracy: 1.0000 - 58ms/epoch - 14ms/step\n",
      "Epoch 27/30\n",
      "4/4 - 0s - loss: 5.7426e-04 - accuracy: 1.0000 - 58ms/epoch - 14ms/step\n",
      "Epoch 28/30\n",
      "4/4 - 0s - loss: 3.9103e-04 - accuracy: 1.0000 - 104ms/epoch - 26ms/step\n",
      "Epoch 29/30\n",
      "4/4 - 0s - loss: 3.1420e-04 - accuracy: 1.0000 - 60ms/epoch - 15ms/step\n",
      "Epoch 30/30\n",
      "4/4 - 0s - loss: 2.4599e-04 - accuracy: 1.0000 - 89ms/epoch - 22ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000023C88FE44C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.3842 - accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3841795921325684, 0.6206896305084229]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import keras for CNN  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "# make CNN model    \n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(X_train_counts.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# feed data to CNN model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train_counts, y_train, batch_size=32, epochs=30, verbose=2)\n",
    "model.evaluate(X_test_counts, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfe12537b1f369a4783f53f558feb30d43af4f7f82409f40c26a1797c6d48cc0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
